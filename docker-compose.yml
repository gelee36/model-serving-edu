version: '3'

services:

  # tf2svg1:    # tf serving CPU, without GPU
  #   #build:
  #   #  context: ./covid19/covid19_models
  #   image: tensorflow/serving
  #   hostname: tf2svg1
  #   environment:
  #     - MODEL_NAME=covid19
  #   restart: on-failure
  #   ports:
  #     - 8511:8501 # tensorflow servring port
  #     - 8510:8500 # grpc port
  #   volumes:
  #     - ./covid19/head-base-covid:/models/covid19

  flask:    # flask server for covid19 service web pages and APIs, with backend tensorflow servering
    build:
      context: ./covid19
    image: ai-service-flask:0.1.0
    hostname: flask
    restart: on-failure
    ports:
      - 5000 # tensorflow servring port
    environment:
      - SERVICE_PORTS=5000
    volumes:
      - ./covid19:/app  # tf2 serving convention
    deploy:
      replicas: 2
    networks:
      - web

  # fastapi:
  #   build:
  #     context: ./covid-fastapi
  #   image: ai-service-fastapi:0.1.0
  #   hostname: fastapi
  #   restart: on-failure
  #   ports:
  #     - 8000
  #   volumes:
  #     - ./covid-fastapi:/app

  proxy:
    image: dockercloud/haproxy
    depends_on:
      - flask
    environment:
      - BALANCE=leastconn
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    ports:
      - 80:80
    networks:
      - web
    deploy:
      placement:
        constraints: [node.role == manager]

networks:
  web:
    driver: overlay
